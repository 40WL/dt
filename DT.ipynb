{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JcCVAGoh9vER"
   },
   "source": [
    "# GENERATING MACHINE LEARNING MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kIftuz39vEU"
   },
   "source": [
    "In this kernel, we will generate a machine learning model decision tree. Some  data preparation tasks need to be performed first as follows:\n",
    "1. Replace null values with median of that column.\n",
    "2. Convert categorical variables to numerical variables.\n",
    "3. Prepare training dan test data.\n",
    "\n",
    "The kernel is based on Kaggle Tutorial: EDA & Machine Learning and Kaggle Tutorial: Your First Machine Learning Model by Hugo-Brown Anderson.\n",
    "\n",
    "In this tutorial, we will generate a decision tree model of Titanic dataset to predict the survival of its passengers.\n",
    "\n",
    "We will use the decision tree implementation from a machine learning library, Scikit Learn.\n",
    "\n",
    "You may need to download and install some libraries e.g. sklearn, seaborn etc. You can use the pip instruction to install the required libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5aoJwFmP9vEV"
   },
   "source": [
    "Import data and check it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "aWalJd3v9vEV"
   },
   "outputs": [],
   "source": [
    "# Import modules\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Figures inline and set visualization style\n",
    "%matplotlib inline\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lcuK5vjC9vEW"
   },
   "source": [
    "Read the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "px6vTA_X9vEW"
   },
   "outputs": [],
   "source": [
    "# Import data\n",
    "df_train = pd.read_csv('data/train-1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "baKEJv_79vEX"
   },
   "source": [
    "Let us see what we have in the dataset. We will print the first 3 rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "buFb_tui9vEX",
    "outputId": "2d16e878-28e8-4331-dd4e-88661300d6cb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ueFS6Tq9vEY"
   },
   "source": [
    "## 1. First, we need to do some preprocessing on the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sip7WCGg9vEY"
   },
   "source": [
    "Do some preprocessing to the dataset. We need to temporarily remove the target class, `Survived`, from the dataset.\n",
    "\n",
    "But first, you'll store the target variable of the training data for safe keeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "KlJK6CuW9vEY"
   },
   "outputs": [],
   "source": [
    "# Store target variable of training data in a safe place\n",
    "survived_train = df_train.Survived\n",
    "\n",
    "# Drop the Survived column\n",
    "data = df_train.drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9sUxUQ319vEZ"
   },
   "source": [
    "Check out your new DataFrame data using the `info()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3NfnevW39vEZ",
    "outputId": "e16e1834-1af4-49b5-bec7-477453c24cdc"
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7jPXDpS9vEZ"
   },
   "source": [
    "Some numerical variables have missing values, `Age` and `Fare`. Some categorical variables are also have missing values; `Cabin` and `Embarked`.\n",
    "\n",
    "Now we will focus on fixing the numerical variables: you will impute or fill in the missing values for those columns, using the median of these variables where you know them. Impute is a process to remove null values in your dataset by replacing them with other values.\n",
    "\n",
    "Note that in this case, you use the median because it's perfect for dealing with outliers. In other words, the median is useful to use when the distribution of data is skewed. Other ways to impute the missing values would be to use the mean, which you can find by adding all data points and dividing by the number of data points, or mode, which is the number that occurs the highest number of times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ZCRZgO_m9vEa"
   },
   "outputs": [],
   "source": [
    "# fill missing values with median column values\n",
    "data.fillna(data.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tjN68NpU9vEa"
   },
   "source": [
    "Now check out the modified data. You can see all the numerical variables are now consists of non-null numerical values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "xRcCbSSU9vEa",
    "outputId": "07ce1976-b9c6-4b10-d168-c2e0254bcb66"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 871 entries, 0 to 870\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    871 non-null int64\n",
      "Pclass         871 non-null int64\n",
      "Name           871 non-null object\n",
      "Sex            871 non-null object\n",
      "Age            871 non-null float64\n",
      "SibSp          871 non-null int64\n",
      "Parch          871 non-null int64\n",
      "Ticket         871 non-null object\n",
      "Fare           871 non-null float64\n",
      "Cabin          199 non-null object\n",
      "Embarked       869 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 74.9+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1hZ1tRV9vEb"
   },
   "source": [
    "Most machine learning models work input features that are numerical. Hence you want to encode your data with numbers, so you'll want to change 'object' dtypes variables to numbers. You can use the pandas function `.get_dummies()` to do so. The `.get_dummies()` allows you to create a new column for each of the options in categorical variables. \n",
    "\n",
    "In this example, we would like to convert the `Sex` attribute to numeric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_V4Bn_ZZ9vEb",
    "outputId": "366c04d4-4666-4a55-d0bf-6e4d41fb4a88",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                               Name  \\\n",
       "0            1       3                            Braund, Mr. Owen Harris   \n",
       "1            2       1  Cumings, Mrs. John Bradley (Florence Briggs Th...   \n",
       "2            3       3                             Heikkinen, Miss. Laina   \n",
       "3            4       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)   \n",
       "4            5       3                           Allen, Mr. William Henry   \n",
       "\n",
       "    Age  SibSp  Parch            Ticket     Fare Cabin Embarked  Sex_male  \n",
       "0  22.0      1      0         A/5 21171   7.2500   NaN        S         1  \n",
       "1  38.0      1      0          PC 17599  71.2833   C85        C         0  \n",
       "2  26.0      0      0  STON/O2. 3101282   7.9250   NaN        S         0  \n",
       "3  35.0      1      0            113803  53.1000  C123        S         0  \n",
       "4  35.0      0      0            373450   8.0500   NaN        S         1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.get_dummies(data, columns=['Sex'], drop_first=True)\n",
    "#data = pd.get_dummies(data, columns=['Sex'])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGOITafm9vEc"
   },
   "source": [
    "`.get_dummies()` allows you to create a new column for each of the options in 'Sex'. So it creates a new column for `female`, called `'Sex_female'`, and then a new column for `'Sex_male'`, which encodes whether that row was male or female.\n",
    "\n",
    "Now, because you added the `drop_first` argument in the line of code above, you dropped `'Sex_female'` because, essentially, these new columns, `'Sex_female'` and `'Sex_male'`, encode the same information.\n",
    "\n",
    "So all you have done is create a new column `'Sex_male'`, which has a 1 if that row is a male - and a 0 if that row is female."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_J2rBfPp9vEc"
   },
   "source": [
    "Now, you'll select the columns `['Sex_male', 'Fare', 'Age','Pclass', 'SibSp']` from your DataFrame to build your first machine learning model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "yihkKpYu9vEc",
    "outputId": "fbdc1904-effd-47c4-9cc6-8873a6e4e4b4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>SibSp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex_male     Fare   Age  Pclass  SibSp\n",
       "0         1   7.2500  22.0       3      1\n",
       "1         0  71.2833  38.0       1      1\n",
       "2         0   7.9250  26.0       3      0\n",
       "3         0  53.1000  35.0       1      1\n",
       "4         1   8.0500  35.0       3      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select columns and view head\n",
    "data = data[['Sex_male', 'Fare', 'Age','Pclass', 'SibSp']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EV3mZOtC9vEc",
    "outputId": "7f7bc16d-c099-4856-fc23-8d2ca0a7fe5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 871 entries, 0 to 870\n",
      "Data columns (total 5 columns):\n",
      "Sex_male    871 non-null uint8\n",
      "Fare        871 non-null float64\n",
      "Age         871 non-null float64\n",
      "Pclass      871 non-null int64\n",
      "SibSp       871 non-null int64\n",
      "dtypes: float64(2), int64(2), uint8(1)\n",
      "memory usage: 28.1 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHcCVa5U9vEd"
   },
   "source": [
    "All the entries are non-null now!\n",
    "\n",
    "Now, you have got your data in a form to build first machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jEYi0mO39vEd"
   },
   "source": [
    "## 2. Build a Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8r8UKe3p9vEd"
   },
   "source": [
    "What is a decision tree classifier? It is a tree that allows you to classify data points, which are also known as target variables, based on feature variables.\n",
    "\n",
    "In this lab, we are using the sklearn tree library to develop our decision tree classifier. Documentation of this library can be found at https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oP-4xqpT9vEd"
   },
   "source": [
    "Before fitting a model to your data, we split it into training and test sets.\n",
    "\n",
    "The training set will be used for the decision tree to learn the dataset. It will output a model or classifier.\n",
    "\n",
    "The test data will be used to test how good the genefrated classifier is.\n",
    "\n",
    "Split the dataset into train and test data. Lets set the test size to 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "StplH5FT9vEe",
    "outputId": "a555f474-55fc-4104-fd54-31a714e27244"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of records in dataset:  871\n",
      "Number of records in training set:  697\n",
      "Number of frecords in test set:  174\n"
     ]
    }
   ],
   "source": [
    "# create training and testing vars\n",
    "msk = np.random.rand(len(data)) < 0.8\n",
    "train = data[msk]\n",
    "train_label = survived_train[msk]\n",
    "test = data[~msk]\n",
    "test_label = survived_train[~msk]\n",
    "\n",
    "print('Number of records in dataset: ', len(data))\n",
    "print('Number of records in training set: ', len(train))\n",
    "print('Number of frecords in test set: ', len(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6rJnL2Jr9vEe"
   },
   "source": [
    "You'll use scikit-learn, which requires your data as arrays, not DataFrames so transform them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ldNAr1_y9vEe"
   },
   "outputs": [],
   "source": [
    "X = train.values\n",
    "y = train_label.values\n",
    "\n",
    "X_test = test.values\n",
    "y_test = test_label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMDycE7e9vEe"
   },
   "source": [
    "Now you get to build your decision tree classifier! First create such a model with `max_depth=3` and then fit it your data. Note that you name your model clf, which is short for \"Classifier\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "M60KYV849vEe",
    "outputId": "1aafce17-9861-4f4a-a1a2-2ef206eebbc8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=4,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=None,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate model and fit to data\n",
    "clf = tree.DecisionTreeClassifier(max_depth=4)\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WO0LMENC9vEf"
   },
   "source": [
    "The feature variables X is the first argument that you pass to the `.fit()` method, while the target variable, y, is the second argument.\n",
    "\n",
    "The output tells you all that you need to know about your Decision Tree Classifier that you just built: as such, you see, for example, that the max depth is set at 3.\n",
    "\n",
    "Now, you'll make predictions on your training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Brr6VfIO9vEf",
    "outputId": "b7d1390f-41ff-45de-fcd9-b03e3b235ea7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:  0.8278335724533716\n",
      "Test accuracy:  0.8505747126436781\n"
     ]
    }
   ],
   "source": [
    "#Compute accuracy on the training set\n",
    "train_accuracy = clf.score(X, y)\n",
    "\n",
    "#Compute accuracy on the testing set\n",
    "test_accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "print('Training accuracy: ', train_accuracy)\n",
    "print('Test accuracy: ', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "APxZxU_69vEf"
   },
   "source": [
    "In the above code, the test_accuracy stores the accuracy of the generated classifier. named clf, in predicting the survival of the passengers listed in the test set.\n",
    "\n",
    "You may improve the accuracy by choosing the suitable `max_depth`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Tc0GXwJ9vEg"
   },
   "source": [
    "### What is `max_depth`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q5o21qXN9vEg"
   },
   "source": [
    "The depth of the tree is known as a hyperparameter, which means a parameter you need to decide before you fit the model to the data. If you choose a larger max_depth, you'll get a more complex decision boundary.\n",
    "\n",
    "    If your decision boundary is too complex, you can overfit to the data, which means that your model will be describing noise as well as signal.\n",
    "\n",
    "    If your max_depth is too small, you might be underfitting the data, meaning that your model doesn't contain enough of the signal.\n",
    "\n",
    "So how  do you identify the best `max_depth`?\n",
    "\n",
    "One way is to hold out a test set from your training data. You can then fit the model to your training data, make predictions on your test set and see how well your prediction does on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "qGfebSwe9vEg"
   },
   "outputs": [],
   "source": [
    "# List of values to try for max_depth:\n",
    "max_depth_range = list(range(1, 6))# List to store the average RMSE for each value of max_depth:\n",
    "accuracy_train = []\n",
    "accuracy_test = []\n",
    "\n",
    "for depth in max_depth_range:    \n",
    "    clf = tree.DecisionTreeClassifier(max_depth = depth, \n",
    "                             random_state = 0)\n",
    "    clf.fit(X, y)    \n",
    "    score = clf.score(X, y)\n",
    "    accuracy_train.append(score)\n",
    "    \n",
    "    score = clf.score(X_test, y_test)\n",
    "    accuracy_test.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hno0fm-j9vEg",
    "outputId": "748d7dfb-60b9-43c4-c4f9-c1e7d9705b36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7819225251076041, 0.7819225251076041, 0.8048780487804879, 0.8278335724533716, 0.8464849354375896]\n",
      "[0.8045977011494253, 0.8045977011494253, 0.8333333333333334, 0.8505747126436781, 0.8620689655172413]\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_train)\n",
    "print(accuracy_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MATn5-Gc_E19"
   },
   "source": [
    "Next we can visualize the generated decision tree. In this example, you will use the existing plot_tree function in sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "hDcDNkek-7dT"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'sklearn.tree' has no attribute 'plot_tree'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d39403910dec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Int this cell, we will use the plot_tree() function in the provided in the sklearn package.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_tree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilled\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'sklearn.tree' has no attribute 'plot_tree'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x864 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "\n",
    "# Int this cell, we will use the plot_tree() function in the provided in the sklearn package.\n",
    "plt.figure(figsize=(20,12))\n",
    "sklearn.tree.plot_tree(clf, filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TEz1Ouqs9vEh"
   },
   "source": [
    "In this tutorial, you have:\n",
    "1. Prepare the data in a form to build a machine learning model.\n",
    "2. Built a machine learning model using a decision tree classifier.\n",
    "3. Makes prediction based on the generated model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_JhRYiB9vEh"
   },
   "source": [
    "# Ungraded assessment\n",
    "\n",
    "## Predict if the unknown passengers are survived/ not survived.\n",
    "\n",
    "These are ungraded questions. Different from the previous lab, submission that produced the best accuracy of prediction will be rewarded. You may form a group of two. I will select three winners, which will be determined based on the accuracy of the prediction, correctness of the code and the time that you need to submit your answer. All the submissions must be accompanied by the runnable code that produced the prediction.\n",
    "\n",
    "Please use the test data provided, 'test-no-label.csv'. Your group are required to predict the 'Survived' label of each of the passenger listed in the test file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kkop0-K_9vEi"
   },
   "outputs": [],
   "source": [
    "!pip install graphviz --user"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
